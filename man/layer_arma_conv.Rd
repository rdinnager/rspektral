% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/layers_conv.R
\name{layer_arma_conv}
\alias{layer_arma_conv}
\title{ARMAConv}
\usage{
layer_arma_conv(
  object,
  channels,
  order = 1,
  iterations = 1,
  share_weights = FALSE,
  gcn_activation = "relu",
  dropout_rate = 0,
  activation = NULL,
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  ...
)
}
\arguments{
\item{channels}{number of output channels}

\item{order}{order of the full ARMA\(_K\) filter, i.e., the number of parallel
stacks in the layer}

\item{iterations}{number of iterations to compute each ARMA\(_1\) approximation}

\item{share_weights}{share the weights in each ARMA\(_1\) stack.}

\item{gcn_activation}{activation function to use to compute each ARMA\(_1\)
stack}

\item{dropout_rate}{dropout rate for skip connection}

\item{activation}{activation function to use}

\item{use_bias}{bool, add a bias vector to the output}

\item{kernel_initializer}{initializer for the weights}

\item{bias_initializer}{initializer for the bias vector}

\item{kernel_regularizer}{regularization applied to the weights}

\item{bias_regularizer}{regularization applied to the bias vector}

\item{activity_regularizer}{regularization applied to the output}

\item{kernel_constraint}{constraint applied to the weights}

\item{bias_constraint}{constraint applied to the bias vector.}
}
\description{
\loadmathjax
A graph convolutional layer with \mjeqn{\mathrm{ARMA} _ K}{} filters, as presented by
\href{https://arxiv.org/abs/1901.01343}{Bianchi et al. (2019)}.

\strong{Mode}: single, disjoint, mixed, batch.

This layer computes:
\mjdeqn{ Z = \frac{1}{K} \sum\limits_{k=1}^K \bar X_k^{(T)}, }{}
where \mjeqn{K}{} is the order of the \mjeqn{\mathrm{ARMA} _ K}{} filter, and where:
\mjdeqn{ \bar X_k^{(t + 1)} = \sigma \left(\tilde L \bar X^{(t)} W^{(t)} + X V^{(t)} \right) }{}
is a recursive approximation of an \mjeqn{\mathrm{ARMA} _ 1}{} filter, where
\mjeqn{ \bar X^{(0)} = X }{}
and
\mjdeqn{ \tilde L =  \frac{2}{\lambda_{max}} \cdot (I - D^{-1/2} A D^{-1/2}) - I }{}
is the normalized Laplacian with a rescaled spectrum.

\strong{Input}
\itemize{
\item Node features of shape \verb{([batch], N, F)};
\item Normalized and rescaled Laplacian of shape \verb{([batch], N, N)}; can be
computed with \code{spektral.utils.convolution.normalized_laplacian} and
\code{spektral.utils.convolution.rescale_laplacian}.
}

\strong{Output}
\itemize{
\item Node features with the same shape as the input, but with the last
dimension changed to \code{channels}.
}
}
