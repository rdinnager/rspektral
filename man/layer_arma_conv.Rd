% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/layers.R
\name{layer_arma_conv}
\alias{layer_arma_conv}
\title{A graph convolutional layer with ARMA\(_K\) filters.}
\usage{
layer_arma_conv(
  object,
  channels,
  order = 1,
  iterations = 1,
  share_weights = FALSE,
  gcn_activation = "relu",
  dropout_rate = 0,
  activation = NULL,
  use_bias = TRUE,
  kernel_initializer = "glorot_uniform",
  bias_initializer = "zeros",
  kernel_regularizer = NULL,
  bias_regularizer = NULL,
  activity_regularizer = NULL,
  kernel_constraint = NULL,
  bias_constraint = NULL,
  ...
)
}
\arguments{
\item{object}{model or layer object;}

\item{channels}{number of output channels;}

\item{order}{order of the full ARMA\(_K\) filter, i.e., the number of parallel
stacks in the layer;}

\item{iterations}{number of iterations to compute each ARMA\(_1\) approximation;}

\item{share_weights}{share the weights in each ARMA\(_1\) stack.}

\item{gcn_activation}{activation function to use to compute each ARMA\(_1\)
stack;}

\item{dropout_rate}{dropout rate for skip connection;}

\item{activation}{activation function to use;}

\item{use_bias}{bool, add a bias vector to the output;}

\item{kernel_initializer}{initializer for the weights;}

\item{bias_initializer}{initializer for the bias vector;}

\item{kernel_regularizer}{regularization applied to the weights;}

\item{bias_regularizer}{regularization applied to the bias vector;}

\item{activity_regularizer}{regularization applied to the output;}

\item{kernel_constraint}{constraint applied to the weights;}

\item{bias_constraint}{constraint applied to the bias vector.}
}
\description{
A graph convolutional layer with ARMA\(\emph{K\) filters, as presented by
\href{https://arxiv.org/abs/1901.01343}{Bianchi et al. (2019)}. \strong{Mode}: single, disjoint, mixed, batch. This layer computes:
$$ \Z = \frac{1}{K} \sum\limits}{k=1}^K \bar\X_k^{(T)},
$$
where \(K\) is the order of the ARMA\(_K\) filter, and where:
$$ \bar \X_k^{(t + 1)} = \sigma \left(\tilde \L \bar \X^{(t)} \W^{(t)} + \X \V^{(t)} \right)
$$
is a recursive approximation of an ARMA\(\emph{1\) filter, where
\( \bar \X^{(0)} = \X \)
and
$$ \tilde \L = \frac{2}{\lambda}{max}} \cdot (\I - \D^{-1/2} \A \D^{-1/2}) - \I
$$
is the normalized Laplacian with a rescaled spectrum. \strong{Input} - Node features of shape \verb{([batch], N, F)};
\itemize{
\item Normalized and rescaled Laplacian of shape \verb{([batch], N, N)}; can be
computed with \code{spektral.utils.convolution.normalized_laplacian} and
\code{spektral.utils.convolution.rescale_laplacian}. \strong{Output} - Node features with the same shape as the input, but with the last
dimension changed to \code{channels}.
}
}
