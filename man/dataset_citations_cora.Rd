% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/datasets.R
\name{dataset_citations_cora}
\alias{dataset_citations_cora}
\title{Citation datasets}
\usage{
dataset_citations_cora(
  dataset_name = "cora",
  normalize_features = TRUE,
  random_split = FALSE
)
}
\arguments{
\item{dataset_name}{name of the dataset to load (\code{'cora'}, \code{'citeseer'}, or
\code{'pubmed'});}

\item{normalize_features}{normalize_features normalize_features: if TRUE,
the node features are normalized;}

\item{random_split}{random_split if TRUE, return a randomized split (20 nodes per class
for training, 30 nodes per class for validation and the remaining nodes for
testing, \href{https://arxiv.org/abs/1811.05868}{Shchur et al. (2018)})}
}
\value{
A list with 6 elements (containing - Adjacency matrix, Node features,
Labels, and 3 binary masks for train, validation, and test splits.)
}
\description{
Loads a citation dataset (Cora, Citeseer or Pubmed) using the "Planetoid"
splits intialliy defined in \href{https://arxiv.org/abs/1603.08861}{Yang et al. (2016)}.
The train, test, and validation splits are given as binary masks. Node attributes are bag-of-words vectors representing the most common words
in the text document associated to each node.
Two papers are connected if either one cites the other.
Labels represent the class of the paper.
}
